{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context:\n",
    "\n",
    "In previous notebook (4-activations...ipynb), we utilized PyTorch's autograd(loss.backwards()) for backpropogation. It's bad to use autograd from frameworks without learning it's internals, becuase we won't know why it's performing well or not. We've implemented our own backpropogation for scalars in micrograd but implementing backpropogation instead of frameworks autograd will help to improve debugging neural nets.\n",
    "As we'll learn the internals of backpropgation it will help more on our undersanding.\n",
    "\n",
    "# Makemore 5: Becoming a backprop ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open(\"names.txt\").read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build dataset\n",
    "block_size = 3 # contet length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate done,to the action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to compare manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embed = 10 # dimensionality of character embedding vectors\n",
    "n_hidden = 64 # number of neurons in hidden layer of MLP\n",
    "torch_seed = 2147483647\n",
    "\n",
    "g = torch.Generator().manual_seed(torch_seed) # for reproducability\n",
    "C = torch.randn(vocab_size, n_embed)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embed * block_size, n_hidden), generator=g) * (5/3)/((n_embed * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # just for understanding, useless because of batch normalization\n",
    "#Layer 2 \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "# Batch norm paramters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1 \n",
    "\n",
    "# Instead of zeros, retaining a samll number, \n",
    "# because sometimes initializing with all zeros could mask an incorrect implementation of backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # shorter variable for conveniance\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3090, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "emb = C[Xb] # embed chars into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenat the vectors\n",
    "\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# BatchNorm layer\n",
    "bnmeani = 1 / n*hprebn.sum(0, keepdim=True) # equivalvelnt of torch.mean(0, keepdim=True)\n",
    "\n",
    "# hprebn - hprebn_mean\n",
    "bndiff = hprebn - bnmeani\n",
    "\n",
    "# Variance - average squared deviations from mean\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction dividing by n-1 not n\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5 # 1 /square roor -> -0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# Cross entropy loss (same as F.cross_entropy(logits))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # Subrac max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,logits,\n",
    "          norm_logits, logit_maxes, h, hpreact, bnraw,\n",
    "          bnvar_inv, bnvar, bndiff2,bndiff, hprebn, bnmeani, embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercis 1: Backpropogating atomic compute graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlogprobs\n",
    "# dlogprobs is logprobs derivate with respect to loss\n",
    "# how loss is influenced by dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.3672, -3.4220, -3.1659, -2.9697, -2.8934, -3.6482, -3.2220, -3.6359,\n",
       "        -4.4542, -3.2220, -3.7647, -2.4836, -2.3280, -3.2694, -3.5567, -3.1493,\n",
       "        -2.9697, -2.4225, -3.3109, -3.6932, -2.9209, -3.5075, -3.9461, -3.8828,\n",
       "        -2.9299, -3.8427, -3.6727, -3.9209, -3.1910, -3.3237, -3.0707, -2.7296],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plucking out correct index for character out of (27) for each input in the batch based on Yb(correct index)\n",
    "# doing a mean of these values and negative\n",
    "logprobs[range(n), Yb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = -(a + b + c)/3\n",
    "# We've 32 characters so which is batch\n",
    "# loss = -(a + b + ....)/32\n",
    "# loss = -a/32 + -b/32 +......\n",
    "# dloss/da = -1/32\n",
    "# -1/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of logprobs where indexes are plucked out is -1/n. What about the other indexes which are not plucked out. Since they don't participate in loss. The derivative of those indices will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "# Setting those indices to 1/n\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs\n",
    "# how probs is affecting logprobs\n",
    "# logprobs is log of probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_10(x)\n",
    "# 1 / x * ln(10)\n",
    "# ln(10) = log_e(10)\n",
    "# e = 2.71288\n",
    "# log(x)\n",
    "# 1 / x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logprobs = probs.log()\n",
    "# dlogprobs/respect to probs == 1/probs ln(probs)\n",
    "# ln(probs) = log_e(probs) where e = 2.71288\n",
    "# torch.log() - uses natural log\n",
    "# So dlogprobs/probs = 1 / probs * local_derivative(by chain rule\n",
    "# dlogprobs/probs = 1 / probs * dlogporbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above derivative, i initially assume torch.log() is base 10 and concluded the derivative of torch.log(x) as 1 / x ln (10).\n",
    "After reading [torch.log](https://pytorch.org/docs/stable/generated/torch.log.html#torch.log) the implementation itself is natural log. Derivate of log(x) will simply be 1/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprobs = 1 / probs * dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dprobs          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dprobs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how probs is affected by counts_sum_inv\n",
    "# probs = counts * counts_sum_inv\n",
    "# dprobs / counts_sum_inv = counts * local_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum_inv = counts * dprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the shapes, in forward pass implict tensor broadcasting is done by PyTorch to perform matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum_inv.shape, dcounts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum_inv.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing a sum at dim 1 to match shape to accomodate tensor broadcasting\n",
    "dcounts_sum_inv = dcounts_sum_inv.sum(1, keepdims=True)\n",
    "dcounts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcounts_sum_inv | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dcounts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_sum with respect to counts_sum_inv\n",
    "# dcounts_sum_inv / dcounts_sum = ??\n",
    "# counts_sum_inv = counts_sum**-1\n",
    "# derivative of x**-1 -> -1/x**2\n",
    "# dcounts_sum_inv / dcounts_sum = -1 / counts_sum ** 2 * dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcounts_sum = (-1.0/counts_sum**2) * dcounts_sum_inv\n",
    "dcounts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapes hold good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcounts\n",
    "# dcounts has two gradients as it influences probs and counts_sum\n",
    "# we'll need dprobs/dcounts and dcounts_sum/dcounts\n",
    "# dprobs/dcounts It's multiplication\n",
    "# dprobs/dcounts = counts_sum_inv * local_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts = counts_sum_inv * dprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcounts.shape, counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcounts_sum/dcounts\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# Derivative of addition is 1, so gradients just passes through\n",
    "# to keep shapes, we'll create ones of counts shape and multiply local gradient with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've to derive array of gradients from counts_sum.\n",
    "Addition just routes local gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# local gradient\n",
    "dcounts_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ones of counts shape\n",
    "torch.ones_like(counts).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting [32, 27] with [32, 1] to create array of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# += to add previous gradinet dprobs/dcount\n",
    "dcounts1 = torch.ones_like(counts) * dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcounts.shape, dcounts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts = dcounts + dcounts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcounts         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dcounts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### norm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = norm_logits.exp()\n",
    "# derivative of exp() is exp() itself\n",
    "# dcounts / dnorm_logits = norm_logits.exp() * dcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnorm_logits = norm_logits.exp() * dcounts\n",
    "dnorm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnorm_logits    | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dnorm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_logits = logits - logit_maxes\n",
    "# dnorm_logits / dlogit_maxes = logits/dlogit_maxes - dlogit_maxex/dlogit_maxes\n",
    "# = - 1 * dnorm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]), torch.Size([32, 27]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_maxes.shape,logits.shape, dnorm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes = -1 * dnorm_logits\n",
    "dlogit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes = dlogit_maxes.sum(1, keepdim=True)\n",
    "dlogit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogit_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dlogit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dlogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits has two dreivatives\n",
    "# dnorm_logits/dlogits and dlogit_maxes / dlogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnorm_logits/dlogits = 1 * dnorm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits = 1.0 * dnorm_logits\n",
    "dlogits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlogit_maxes / dlogits\n",
    "# torch.max() takes max of the dimension\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# 0th dimension has zero gradients and 1th dimension has gradient of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_logit_maxes = torch.zeros_like(logits)\n",
    "dlogits_logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.]])"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_logit_maxes[range(n), logits.max(1).indices] = 1.0\n",
    "dlogits_logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd465cbd120>"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(dlogits_logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_logit_maxes.shape, dlogit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor broadcasting makse sure that dlogit_maxes values are forwarded only\n",
    "# on the bits turned on in dlogits_logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits_logit_maxes = dlogits_logit_maxes * dlogit_maxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits += dlogits_logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dlogits', dlogits, logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dh, dW2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how h inflluences logits\n",
    "# local gradient --> dlogits\n",
    "# logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 27]),\n",
       " torch.Size([27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 27]))"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape, b2.shape, h.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0143, -0.0895, -0.0872,  ...,  0.0151, -0.0417,  0.0593],\n",
       "        [-0.0297,  0.0812, -0.0663,  ..., -0.0527,  0.1308,  0.2315],\n",
       "        [ 0.0256,  0.0271,  0.2262,  ...,  0.1242,  0.0248, -0.0531],\n",
       "        ...,\n",
       "        [-0.1393,  0.1201, -0.1010,  ..., -0.0118, -0.0138,  0.0103],\n",
       "        [-0.1787, -0.1160,  0.1549,  ..., -0.0052, -0.1179, -0.1299],\n",
       "        [-0.0749, -0.0890, -0.1501,  ..., -0.0905, -0.1335,  0.0851]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt dh1](images/dh1.jpeg)\n",
    "![Alt dh2](images/dh2.jpeg)\n",
    "![Alt dh3](images/dh3.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 27]),\n",
       " torch.Size([27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 27]))"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the shapes again\n",
    "W2.shape, b2.shape, h.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know local gradient is dlogits-> [32, 27]\n",
    "# shape of h which is shape of dh -> [32, 64]\n",
    "# To get this shape, we've to transpose W2 [64, 27] -> [27, 64]\n",
    "# Multiplying these which is dlogits @ W2T we arrive at the derived formula above\n",
    "dh = dlogits @ W2.T\n",
    "# Similarly\n",
    "dW2 = h.T @ dlogits\n",
    "# db2 -> sum of dlogits\n",
    "# b2 shape -> [27]\n",
    "# dlogits shape -> [32, 27]\n",
    "# sum at 0 axis will give desired shape which is deerivate as well\n",
    "db2 = dlogits.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 27]), torch.Size([64, 27]))"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2.shape, W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dhpreact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dhpreact == ?\n",
    "# localgradient = dh\n",
    "# h = torch.tanh(hpreact)\n",
    "# dh/dhpreact = 1 - h**2 * dh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt derivativeoftanh](http://ronny.rest/media/blog/2017/2017_08_16_tanh/tanh_and_derivative_formulas.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of tanh is 1 - output**2\n",
    "# here output is h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.shape, dh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhpreact = (1 - h**2) * dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhpreact        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dhpreact\", dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbngain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how bngain impacts hpreact\n",
    "# localgradient -> dhpreact\n",
    "# dhpreact/dbngain = bnraw * dhpreact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking out shapes\n",
    "bngain.shape, dhpreact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbngain = bnraw * dhpreact\n",
    "dbngain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbngain = dbngain.sum(0, keepdim=True)\n",
    "dbngain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbngain         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbngain\", dbngain, bngain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbnbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how bnbias impacts hpreact\n",
    "# local gradient -> dhpreact\n",
    "# dhpreact/dbnbias = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at shapes\n",
    "bnbias.shape, dhpreact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnbias = dhpreact.clone().sum(0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnbias         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbnbias\", dbnbias, bnbias)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbnraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How bnraw impacts hpreact\n",
    "# localgradient = dhpreact\n",
    "# dhpreact / dbnraw = bngain * dhpreact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out shpaes\n",
    "dhpreact.shape, bnraw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnraw = bngain * dhpreact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnraw          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbnraw\", dbnraw, bnraw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how bnvar_inv impacts bnraw\n",
    "# local gradient -> dbnraw\n",
    "# dbnraw/dbnvar_inv = bndiff * dbnraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at shapes\n",
    "bndiff.shape, dbnraw.shape, bnvar_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnvar_inv      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbnvar_inv\", dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how bnvar affects bnvar_inv\n",
    "# local gradient -> dbnvar_inv\n",
    "# dbnvar = -0.5 * (bnvar + 1e-5)**-1.5\n",
    "# power rule d/dx x**n = nx**n-1\n",
    "# plus chain rule on bnvar + 1e-5\n",
    "# Since it's addition derivative of this is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking shapes\n",
    "dbnvar_inv.shape,bnvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnvar          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbnvar\", dbnvar, bnvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bndiff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff2.shape,bnvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([193.5311], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff2[0].sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's essentially occuring is sum along 0'th axis of bnvar\n",
    "# multiplied by 1 /(n-1)\n",
    "# differentiation of addition is 1\n",
    "# dbnvar = 1/n-1 * torch.ones_like(bndiff2) -> for replication * dbnvar\n",
    "# local gradient -> bnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the shape of bndiff, since derivatives are 1\n",
    "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above we allowef broadcasting to take care of shape for us\n",
    "# bndiff2 -> (32, 64)\n",
    "# dbnvar -> (1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"bndiff2\", dbndiff2, bndiff2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbndiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How bndiff impacts bndiff2\n",
    "# bndiff2 = bnidff**2\n",
    "# local gradient = dbndiff2\n",
    "# dbndiff2/dbndiff = 2nbdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at shapes\n",
    "bndiff.shape, dbndiff2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st derivative\n",
    "dbndiff = (2.0 * bndiff) * dbndiff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd derivative\n",
    "dbndiff += bnvar_inv * dbnraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbndiff         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbndiff\", dbndiff, bndiff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbnmeani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how bnmeani impacts bndiff\n",
    "# local gradient = dbndiff\n",
    "# bndiff = hprebn - bnmeani\n",
    "# dbndiff/dbnmeani = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shapes\n",
    "bnmeani.shape, dbndiff.shape, hprebn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hprebn - bmeani has a broadcsting in forward pass\n",
    "# we've have to do a sum in backward pass to acheived bmeani shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnmeani = (-1.0 * dbndiff).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbmeani\", dbnmeani, bnmeani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dhprebn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([64]))"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape, dbnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to dbnvar\n",
    "# treat 1/n*hprebn as x with sum along 0th dimension\n",
    "# gradient will be 1 /n \n",
    "\n",
    "### Derivation\n",
    "# bnmeani = 1 / n*hprebn_11 + 1/n*hprebn_12...\n",
    "# diff with respect to 11\n",
    "# dbnmeani/dhprebn_11 = 1/n*hprebn_11 * dhprebn_11\n",
    "# => 1\n",
    "###\n",
    "\n",
    "# local gradient -> dbnmeani\n",
    "# To achieve shape replicaton with ones_like(on hprebn)\n",
    "# Note: We've sum in forward pass replication in backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn = (1.0/n) * torch.ones_like(hprebn) * dbnmeani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhprebn         | exact: False | approximate: False | maxdiff: 0.006330112461000681\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dhprebn\", dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WE also have another derivative of hprebn with respec to bndiff\n",
    "# graident 1\n",
    "# local gradient dndiff\n",
    "dbndiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn += dbndiff.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhprebn         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dhprebn\", dhprebn, hprebn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dembcat, dW1, db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([32, 64]))"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should be similar to h\n",
    "# local gradient -> dhprebn\n",
    "# let's check the shapes\n",
    "embcat.shape, W1.shape, b1.shape, dhprebn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]), torch.Size([32, 30]))"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To achieve embcat shape for dembcat\n",
    "dembcat = dhprebn @ W1.T\n",
    "dembcat.shape, embcat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dembcat         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dembcat\", dembcat, embcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW1             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# To achieve W1 shape (30, 64)\n",
    "# Transpose of embcat(30, 32) @ dhprebn (32, 64)\n",
    "dW1 = embcat.T @ dhprebn\n",
    "cmp(\"dW1\", dW1, W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To acheive db1 shpe (64) sum along 0th axis of  dhprebn\n",
    "# with keepdim False\n",
    "db1 = dhprebn.sum(0)\n",
    "db1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db1             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"db1\", db1, b1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]), torch.Size([32, 3, 10]))"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dembcat.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb influences embcat only via shape change using view\n",
    "# restoring demb to emb shape should be the gradients of emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demb            | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "demb = dembcat.view(32, 3, 10)\n",
    "cmp(\"demb\", demb, emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27, 10]), torch.Size([32, 3]), torch.Size([32, 3, 10]))"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape, Xb.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([11,  9, 14]),\n",
       " tensor([ 1.4637,  0.8825, -0.5186, -1.1843, -1.7660,  1.0399, -0.7417, -0.8340,\n",
       "         -0.5230,  1.4915], grad_fn=<SelectBackward0>),\n",
       " tensor([ 0.9476,  1.9691, -0.1976, -1.0895, -0.5194, -0.1681,  0.5862,  0.4005,\n",
       "          1.4364,  1.7788], grad_fn=<SelectBackward0>),\n",
       " tensor([-1.4296, -0.1619, -0.0187,  0.6729, -2.1133,  0.1974, -1.5864, -0.3398,\n",
       "         -1.6136,  0.7019], grad_fn=<SelectBackward0>),\n",
       " tensor([[ 1.4637,  0.8825, -0.5186, -1.1843, -1.7660,  1.0399, -0.7417, -0.8340,\n",
       "          -0.5230,  1.4915],\n",
       "         [ 0.9476,  1.9691, -0.1976, -1.0895, -0.5194, -0.1681,  0.5862,  0.4005,\n",
       "           1.4364,  1.7788],\n",
       "         [-1.4296, -0.1619, -0.0187,  0.6729, -2.1133,  0.1974, -1.5864, -0.3398,\n",
       "          -1.6136,  0.7019]], grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb[0], C[11], C[9], C[14], emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In forward pass, we've looked up embedding of Xb from C\n",
    "# Now we've to route the gradients of each Xb index to dC\n",
    "# We'll have additive sum because a single index is looked up\n",
    "# multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC = torch.zeros_like(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[i, j]\n",
    "        # index of lookup to demb(gradients)\n",
    "        dC[ix] += demb[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dc              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dc\", dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = 1/probs * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
    "dcounts_sum = (-1.0/counts_sum**2) * dcounts_sum_inv\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits =  dnorm_logits.clone() # equivalent to 1 * dnorm_logits\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdims=True)\n",
    "# Another way of implementing \n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdims=True)\n",
    "dbnbias = dhpreact.clone().sum(0, keepdims=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdims=True)\n",
    "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff = (2.0 * bndiff) * dbndiff2\n",
    "dbndiff += bnvar_inv * dbnraw\n",
    "dbnmeani = (-1.0 * dbndiff).sum(0, keepdims=True)\n",
    "dhprebn = (1.0/n) * torch.ones_like(hprebn) * dbnmeani\n",
    "dhprebn += dbndiff.clone()\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(32, 3, 10)\n",
    "dC = torch.zeros_like(C)\n",
    "for i in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[i, j]\n",
    "        # index of lookup to demb(gradients)\n",
    "        dC[ix] += demb[i, j]\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy loss backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3089685440063477 diff: -2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast-loss).item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt crossentropy1](images/cross_entropy_1.jpeg)\n",
    "![Alt crossentropy1](images/cross_entropy_2.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on derivation\n",
    "# dlogits = Softmax(logits, 1) when logits != label\n",
    "# dlogits = dlogits - 1 where logits == label \n",
    "# For a batch loss is average of above loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.4928, -0.7982, -0.4846, -0.5426,  0.0813,  0.2395,  1.3984,  0.2634,\n",
       "         -0.8400,  0.4568, -0.1791, -0.5536,  0.4022, -0.4001,  0.2706,  0.7215,\n",
       "         -0.2160, -0.1013, -0.6098,  1.3226,  0.3050, -0.1212, -1.2826, -0.3391,\n",
       "          1.1639,  0.7651, -0.9461], grad_fn=<SelectBackward0>),\n",
       " tensor([0.1179, 0.0119, 0.0163, 0.0154, 0.0287, 0.0337, 0.1073, 0.0345, 0.0114,\n",
       "         0.0418, 0.0222, 0.0152, 0.0396, 0.0178, 0.0347, 0.0545, 0.0214, 0.0239,\n",
       "         0.0144, 0.0995, 0.0360, 0.0235, 0.0073, 0.0189, 0.0849, 0.0570, 0.0103],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0], dlogits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0809, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax implementation for logits_i(logits at ith index)\n",
    "torch.exp(torch.tensor(1.1158)) / torch.exp(logits[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0000, grad_fn=<SumBackward0>),\n",
       " tensor(1.4688, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax sum is 1\n",
    "dlogits[0].sum(), logits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1179,  0.0119,  0.0163,  0.0154,  0.0287,  0.0337,  0.1073, -0.9655,\n",
       "         0.0114,  0.0418,  0.0222,  0.0152,  0.0396,  0.0178,  0.0347,  0.0545,\n",
       "         0.0214,  0.0239,  0.0144,  0.0995,  0.0360,  0.0235,  0.0073,  0.0189,\n",
       "         0.0849,  0.0570,  0.0103], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.983"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dlogit at index 7\n",
    "0.0170 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average\n",
    "dlogits /= n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: False | approximate: True  | maxdiff: 8.847564458847046e-09\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dlogits\", dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlabel(\"Characters\")\n",
    "plt.ylabel(\"Batch of inputs\")\n",
    "plt.imshow(dlogits.detach(), cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.7253e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On visualizing the logits, if we see the 0th index at y axis(inputs) 7th index of x axis(27 characters) is negative -0.983 so highlighted in dark black.\n",
    "\n",
    "The derivatives are the gradients.\n",
    "\n",
    "What's essentially happending with derivatives is, we're pulling down the wrong probabalites(gray colored) and pulling up the correct probabalities(black colored). Since the sum of gradient across an input is zero, the push and pull are identitical.\n",
    "\n",
    "The neural network acts like a pulley system to push and pull gradients, which in turn affects the weight and biases. The push and pull is proportional to the corret and incorrect answer (i.e) probabalities in forward pass.\n",
    "\n",
    "> The amount of push pull in a dimension is proportinal to incorrect probabalities. The incorrectness is calculated by cross_entropy loss."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization in one go"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt bn1](images/bn1.jpg)\n",
    "![Alt bn2](images/bn2.jpg)\n",
    "![Alt bn3](images/bn3.jpg)\n",
    "![Alt bn4](images/bn4.jpg)\n",
    "![Alt bn5](images/bn5.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn = bngain * bnvar_inv/n * (n * dhpreact - dhpreact.sum(0) - n/(n-1) * bnraw * (dhpreact* bnraw).sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking broadcasting\n",
    "dhpreact.shape, dhpreact.sum(0).shape, bnraw.shape, dhprebn.shape, bngain.shape, bnvar_inv.shape, (dhpreact* bnraw).sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhprebn         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dhprebn\", dhprebn, hprebn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing loss.backward() with manual gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n",
      "     31/ 200000: 3.345981\n"
     ]
    }
   ],
   "source": [
    "n_embed = 10 # dimensionality of character embedding vectors\n",
    "n_hidden = 64 # number of neurons in hidden layer of MLP\n",
    "torch_seed = 2147483647\n",
    "\n",
    "g = torch.Generator().manual_seed(torch_seed) # for reproducability\n",
    "C = torch.randn(vocab_size, n_embed)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embed * block_size, n_hidden), generator=g) * (5/3)/((n_embed * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # just for understanding, useless because of batch normalization\n",
    "#Layer 2 \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "# Batch norm paramters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1 \n",
    "\n",
    "# Instead of zeros, retaining a samll number, \n",
    "# because sometimes initializing with all zeros could mask an incorrect implementation of backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size\n",
    "lossi = []\n",
    "\n",
    "for epoch in range(200000):\n",
    "\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "    emb = C[Xb] # embed chars into vectors \n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenat the vectors\n",
    "\n",
    "    # Linear layer 1\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "    # BatchNorm layer\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    ######\n",
    "\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    # Linear layer 2\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    # Cross entropy loss (same as F.cross_entropy(logits))\n",
    "    loss = F.cross_entropy(logits, Yb)\n",
    "\n",
    "    # PyTorch backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward() # For compaarison\n",
    "\n",
    "    #### Manul backprop\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # batch norm backprop\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(32, 3, 10)\n",
    "    dC = torch.zeros_like(C)\n",
    "\n",
    "    for i in range(Xb.shape[0]):\n",
    "        for j in range(Xb.shape[1]):\n",
    "            ix = Xb[i, j]\n",
    "            # index of lookup to demb(gradients)\n",
    "            dC[ix] += demb[i, j]\n",
    "\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "\n",
    "    # Update\n",
    "    lr = 0.1 if epoch < 100000 else 0.01\n",
    "    # Loss.backward() update for comparison\n",
    "    for p, grad in zip(parameters, grads):\n",
    "        p.data += -lr * p.grad\n",
    "        # p.data += -lr * grad # grads from manual gradient\n",
    "\n",
    "    if epoch % 10000 == 0:\n",
    "        print(f\"{i:7d}/{max_steps:7d}: {loss.item():4f}\")\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "    if epoch > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 10)        | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "(30, 64)        | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "(64,)           | exact: False | approximate: True  | maxdiff: 6.51925802230835e-09\n",
      "(64, 27)        | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "(27,)           | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "(1, 64)         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "(1, 64)         | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
     ]
    }
   ],
   "source": [
    "# Comparing gradients\n",
    "for p, g in zip(parameters, grads):\n",
    "    cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've achieved the full gradiens in one-got and it's approximate is true. Let's remove loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n",
      "     31/ 200000: 3.314781\n",
      "     31/ 200000: 2.578549\n",
      "     31/ 200000: 2.372112\n",
      "     31/ 200000: 2.332455\n",
      "     31/ 200000: 2.070600\n",
      "     31/ 200000: 2.110276\n",
      "     31/ 200000: 2.200143\n",
      "     31/ 200000: 2.348270\n",
      "     31/ 200000: 2.454972\n",
      "     31/ 200000: 2.300684\n",
      "     31/ 200000: 2.247980\n",
      "     31/ 200000: 2.303355\n",
      "     31/ 200000: 2.189549\n",
      "     31/ 200000: 1.841415\n",
      "     31/ 200000: 2.478203\n",
      "     31/ 200000: 1.931649\n",
      "     31/ 200000: 2.374298\n",
      "     31/ 200000: 2.157724\n",
      "     31/ 200000: 2.241688\n",
      "     31/ 200000: 2.166559\n"
     ]
    }
   ],
   "source": [
    "n_embed = 10 # dimensionality of character embedding vectors\n",
    "n_hidden = 64 # number of neurons in hidden layer of MLP\n",
    "torch_seed = 2147483647\n",
    "\n",
    "g = torch.Generator().manual_seed(torch_seed) # for reproducability\n",
    "C = torch.randn(vocab_size, n_embed)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embed * block_size, n_hidden), generator=g) * (5/3)/((n_embed * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # just for understanding, useless because of batch normalization\n",
    "#Layer 2 \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "# Batch norm paramters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1 \n",
    "\n",
    "# Instead of zeros, retaining a samll number, \n",
    "# because sometimes initializing with all zeros could mask an incorrect implementation of backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size\n",
    "lossi = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for epoch in range(200000):\n",
    "\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "        emb = C[Xb] # embed chars into vectors \n",
    "        embcat = emb.view(emb.shape[0], -1) # concatenat the vectors\n",
    "\n",
    "        # Linear layer 1\n",
    "        hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "        # BatchNorm layer\n",
    "        bnmean = hprebn.mean(0, keepdim=True)\n",
    "        bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "        bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "        bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "        hpreact = bngain * bnraw + bnbias\n",
    "        ######\n",
    "\n",
    "        # Non-linearity\n",
    "        h = torch.tanh(hpreact) # hidden layer\n",
    "        # Linear layer 2\n",
    "        logits = h @ W2 + b2 # output layer\n",
    "        # Cross entropy loss (same as F.cross_entropy(logits))\n",
    "        loss = F.cross_entropy(logits, Yb)\n",
    "\n",
    "        # PyTorch backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "\n",
    "        #### Manul backprop\n",
    "        dlogits = F.softmax(logits, 1)\n",
    "        dlogits[range(n), Yb] -= 1\n",
    "        dlogits /= n\n",
    "        # 2nd layer backprop\n",
    "        dh = dlogits @ W2.T\n",
    "        dW2 = h.T @ dlogits\n",
    "        db2 = dlogits.sum(0)\n",
    "        # batch norm backprop\n",
    "        dhpreact = (1.0 - h**2) * dh\n",
    "        dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "        dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "        dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "        dembcat = dhprebn @ W1.T\n",
    "        dW1 = embcat.T @ dhprebn\n",
    "        db1 = dhprebn.sum(0)\n",
    "        # embedding\n",
    "        demb = dembcat.view(32, 3, 10)\n",
    "        dC = torch.zeros_like(C)\n",
    "\n",
    "        for i in range(Xb.shape[0]):\n",
    "            for j in range(Xb.shape[1]):\n",
    "                ix = Xb[i, j]\n",
    "                # index of lookup to demb(gradients)\n",
    "                dC[ix] += demb[i, j]\n",
    "\n",
    "        grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "\n",
    "        # Update\n",
    "        lr = 0.1 if epoch < 100000 else 0.01\n",
    "        # Loss.backward() update for comparison\n",
    "        for p, grad in zip(parameters, grads):\n",
    "            # p.data += -lr * p.grad # loss.backward()\n",
    "            p.data += -lr * grad # grads from manual gradient\n",
    "\n",
    "        if epoch % 10000 == 0:\n",
    "            print(f\"{epoch:7d}/{max_steps:7d}: {loss.item():4f}\")\n",
    "        lossi.append(loss.log10().item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumb mistake in not replacing i with epoch. So all the epochs come as 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carmahela.\n",
      "jheri.\n",
      "kimri.\n",
      "reh.\n",
      "cassanden.\n",
      "jazonte.\n",
      "den.\n",
      "rha.\n",
      "kaqui.\n",
      "ner.\n",
      "kiarceriivin.\n",
      "leig.\n",
      "dham.\n",
      "join.\n",
      "quint.\n",
      "suline.\n",
      "liveni.\n",
      "waatho.\n",
      "dearyxia.\n",
      "kaellius.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I've tried to learn differentiation and how the gradients are flowing through in backwad pass at a very granular level.\n",
    "And achieved backward propogation without PyTorch's autograd engine.\n",
    "This brings us to closure of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "21a124e163c92121797d725bed844fa6fdaf2c4e47bf1f149ef174ae791c682a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
