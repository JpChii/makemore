{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context:\n",
    "\n",
    "In previous notebook (4-activations...ipynb), we utilized PyTorch's autograd(loss.backwards()) for backpropogation. It's bad to use autograd from frameworks without learning it's internals, becuase we won't know why it's performing well or not. We've implemented our own backpropogation for scalars in micrograd but implementing backpropogation instead of frameworks autograd will help to improve debugging neural nets.\n",
    "As we'll learn the internals of backpropgation it will help more on our undersanding.\n",
    "\n",
    "# Makemore 5: Becoming a backprop ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open(\"names.txt\").read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build dataset\n",
    "block_size = 3 # contet length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate done,to the action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to compare manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embed = 10 # dimensionality of character embedding vectors\n",
    "n_hidden = 64 # number of neurons in hidden layer of MLP\n",
    "torch_seed = 2147483647\n",
    "\n",
    "g = torch.Generator().manual_seed(torch_seed) # for reproducability\n",
    "C = torch.randn(vocab_size, n_embed)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embed * block_size, n_hidden), generator=g) * (5/3)/((n_embed * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # just for understanding, useless because of batch normalization\n",
    "#Layer 2 \n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "# Batch norm paramters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1 \n",
    "\n",
    "# Instead of zeros, retaining a samll number, \n",
    "# because sometimes initializing with all zeros could mask an incorrect implementation of backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # shorter variable for conveniance\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3746, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "emb = C[Xb] # embed chars into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenat the vectors\n",
    "\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# BatchNorm layer\n",
    "bnmeani = 1 / n*hprebn.sum(0, keepdim=True) # equivalvelnt of torch.mean(0, keepdim=True)\n",
    "\n",
    "# hprebn - hprebn_mean\n",
    "bndiff = hprebn - bnmeani\n",
    "\n",
    "# Variance - average squared deviations from mean\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction dividing by n-1 not n\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5 # 1 /square roor -> -0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# Cross entropy loss (same as F.cross_entropy(logits))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # Subrac max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,logits,\n",
    "          norm_logits, logit_maxes, h, hpreact, bnraw,\n",
    "          bnvar_inv, bnvar, bndiff2,bndiff, hprebn, bnmeani, embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercis 1: Backpropogating atomic compute graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlogprobs\n",
    "# dlogprobs is logprobs derivate with respect to loss\n",
    "# how loss is influenced by dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.0727, -4.4074, -3.9848, -3.1296, -3.2392, -3.5740, -2.8305, -2.6719,\n",
       "        -3.5799, -2.8305, -4.2648, -2.8558, -3.7718, -3.6642, -2.7077, -2.5011,\n",
       "        -3.1296, -3.4934, -2.6305, -3.3983, -3.7924, -3.9651, -3.6471, -2.7239,\n",
       "        -3.3477, -3.6170, -3.3558, -3.0702, -3.0781, -3.1848, -3.7052, -3.7633],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plucking out correct index for character out of (27) for each input in the batch based on Yb(correct index)\n",
    "# doing a mean of these values and negative\n",
    "logprobs[range(n), Yb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = -(a + b + c)/3\n",
    "# We've 32 characters so which is batch\n",
    "# loss = -(a + b + ....)/32\n",
    "# loss = -a/32 + -b/32 +......\n",
    "# dloss/da = -1/32\n",
    "# -1/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of logprobs where indexes are plucked out is -1/n. What about the other indexes which are not plucked out. Since they don't participate in loss. The derivative of those indices will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "# Setting those indices to 1/n\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs\n",
    "# how probs is affecting logprobs\n",
    "# logprobs is log of probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_10(x)\n",
    "# 1 / x * ln(10)\n",
    "# ln(10) = log_e(10)\n",
    "# e = 2.71288\n",
    "# log(x)\n",
    "# 1 / x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logprobs = probs.log()\n",
    "# dlogprobs/respect to probs == 1/probs ln(probs)\n",
    "# ln(probs) = log_e(probs) where e = 2.71288\n",
    "# torch.log() - uses natural log\n",
    "# So dlogprobs/probs = 1 / probs * local_derivative(by chain rule\n",
    "# dlogprobs/probs = 1 / probs * dlogporbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above derivative, i initially assume torch.log() is base 10 and concluded the derivative of torch.log(x) as 1 / x ln (10).\n",
    "After reading [torch.log](https://pytorch.org/docs/stable/generated/torch.log.html#torch.log) the implementation itself is natural log. Derivate of log(x) will simply be 1/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprobs = 1 / probs * dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dprobs          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dprobs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how probs is affected by counts_sum_inv\n",
    "# probs = counts * counts_sum_inv\n",
    "# dprobs / counts_sum_inv = counts * local_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum_inv = counts * dprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the shapes, in forward pass implict tensor broadcasting is done by PyTorch to perform matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum_inv.shape, dcounts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum_inv.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing a sum at dim 1 to match shape to accomodate tensor broadcasting\n",
    "dcounts_sum_inv = dcounts_sum_inv.sum(1, keepdims=True)\n",
    "dcounts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcounts_sum_inv | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dcounts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_sum with respect to counts_sum_inv\n",
    "# dcounts_sum_inv / dcounts_sum = ??\n",
    "# counts_sum_inv = counts_sum**-1\n",
    "# derivative of x**-1 -> -1/x**2\n",
    "# dcounts_sum_inv / dcounts_sum = -1 / counts_sum ** 2 * dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_sum.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcounts_sum = (-1.0/counts_sum**2) * dcounts_sum_inv\n",
    "dcounts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapes hold good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcounts\n",
    "# dcounts has two gradients as it influences probs and counts_sum\n",
    "# we'll need dprobs/dcounts and dcounts_sum/dcounts\n",
    "# dprobs/dcounts It's multiplication\n",
    "# dprobs/dcounts = counts_sum_inv * local_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts = counts_sum_inv * dprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcounts.shape, counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcounts_sum/dcounts\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# Derivative of addition is 1, so gradients just passes through\n",
    "# to keep shapes, we'll create ones of counts shape and multiply local gradient with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've to derive array of gradients from counts_sum.\n",
    "Addition just routes local gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# local gradient\n",
    "dcounts_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ones of counts shape\n",
    "torch.ones_like(counts).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting [32, 27] with [32, 1] to create array of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# += to add previous gradinet dprobs/dcount\n",
    "dcounts1 = torch.ones_like(counts) * dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcounts.shape, dcounts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts = dcounts + dcounts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcounts         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dcounts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### norm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = norm_logits.exp()\n",
    "# derivative of exp() is exp() itself\n",
    "# dcounts / dnorm_logits = norm_logits.exp() * dcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnorm_logits = norm_logits.exp() * dcounts\n",
    "dnorm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnorm_logits    | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dnorm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_logits = logits - logit_maxes\n",
    "# dnorm_logits / dlogit_maxes = logits/dlogit_maxes - dlogit_maxex/dlogit_maxes\n",
    "# = - 1 * dnorm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]), torch.Size([32, 27]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_maxes.shape,logits.shape, dnorm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes = -1 * dnorm_logits\n",
    "dlogit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes = dlogit_maxes.sum(1, keepdim=True)\n",
    "dlogit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogit_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dlogit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dlogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits has two dreivatives\n",
    "# dnorm_logits/dlogits and dlogit_maxes / dlogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnorm_logits/dlogits = 1 * dnorm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits = 1.0 * dnorm_logits\n",
    "dlogits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlogit_maxes / dlogits\n",
    "# torch.max() takes max of the dimension\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# 0th dimension has zero gradients and 1th dimension has gradient of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_logit_maxes = torch.zeros_like(logits)\n",
    "dlogits_logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_logit_maxes[range(n), logits.max(1).indices] = 1.0\n",
    "dlogits_logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc28a02d090>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(dlogits_logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits_logit_maxes.shape, dlogit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor broadcasting makse sure that dlogit_maxes values are forwarded only\n",
    "# on the bits turned on in dlogits_logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits_logit_maxes = dlogits_logit_maxes * dlogit_maxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits += dlogits_logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('dlogits', dlogits, logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dh, dW2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how h inflluences logits\n",
    "# local gradient --> dlogits\n",
    "# logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 27]),\n",
       " torch.Size([27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 27]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape, b2.shape, h.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0143, -0.0895, -0.0872,  ...,  0.0151, -0.0417,  0.0593],\n",
       "        [-0.0297,  0.0812, -0.0663,  ..., -0.0527,  0.1308,  0.2315],\n",
       "        [ 0.0256,  0.0271,  0.2262,  ...,  0.1242,  0.0248, -0.0531],\n",
       "        ...,\n",
       "        [-0.1393,  0.1201, -0.1010,  ..., -0.0118, -0.0138,  0.0103],\n",
       "        [-0.1787, -0.1160,  0.1549,  ..., -0.0052, -0.1179, -0.1299],\n",
       "        [-0.0749, -0.0890, -0.1501,  ..., -0.0905, -0.1335,  0.0851]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt dh1](images/dh1.jpeg)\n",
    "![Alt dh2](images/dh2.jpeg)\n",
    "![Alt dh3](images/dh3.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 27]),\n",
       " torch.Size([27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([32, 27]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the shapes again\n",
    "W2.shape, b2.shape, h.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know local gradient is dlogits-> [32, 27]\n",
    "# shape of h which is shape of dh -> [32, 64]\n",
    "# To get this shape, we've to transpose W2 [64, 27] -> [27, 64]\n",
    "# Multiplying these which is dlogits @ W2T we arrive at the derived formula above\n",
    "dh = dlogits @ W2.T\n",
    "# Similarly\n",
    "dW2 = h.T @ dlogits\n",
    "# db2 -> sum of dlogits\n",
    "# b2 shape -> [27]\n",
    "# dlogits shape -> [32, 27]\n",
    "# sum at 0 axis will give desired shape which is deerivate as well\n",
    "db2 = dlogits.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 27]), torch.Size([64, 27]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2.shape, W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dhpreact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dhpreact == ?\n",
    "# localgradient = dh\n",
    "# h = torch.tanh(hpreact)\n",
    "# dh/dhpreact = 1 - h**2 * dh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt derivativeoftanh](http://ronny.rest/media/blog/2017/2017_08_16_tanh/tanh_and_derivative_formulas.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of tanh is 1 - output**2\n",
    "# here output is h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.shape, dh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhpreact = (1 - h**2) * dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhpreact        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dhpreact\", dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbngain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how bngain impacts hpreact\n",
    "# localgradient -> dhpreact\n",
    "# dhpreact/dbngain = bnraw * dhpreact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking out shapes\n",
    "bngain.shape, dhpreact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbngain = bnraw * dhpreact\n",
    "dbngain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbngain = dbngain.sum(0, keepdim=True)\n",
    "dbngain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbngain         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbngain\", dbngain, bngain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbnbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how bnbias impacts hpreact\n",
    "# local gradient -> dhpreact\n",
    "# dhpreact/dbnbias = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at shapes\n",
    "bnbias.shape, dhpreact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnbias = dhpreact.clone().sum(0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnbias         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbnbias\", dbnbias, bnbias)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbnraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How bnraw impacts hpreact\n",
    "# localgradient = dhpreact\n",
    "# dhpreact / dbnraw = bngain * dhpreact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out shpaes\n",
    "dhpreact.shape, bnraw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnraw = bngain * dhpreact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnraw          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbnraw\", dbnraw, bnraw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how bnvar_inv impacts bnraw\n",
    "# local gradient -> dbnraw\n",
    "# dbnraw/dbnvar_inv = bndiff * dbnraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at shapes\n",
    "bndiff.shape, dbnraw.shape, bnvar_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnvar_inv      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbnvar_inv\", dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how bnvar affects bnvar_inv\n",
    "# local gradient -> dbnvar_inv\n",
    "# dbnvar = -0.5 * (bnvar + 1e-5)**-1.5\n",
    "# power rule d/dx x**n = nx**n-1\n",
    "# plus chain rule on bnvar + 1e-5\n",
    "# Since it's addition derivative of this is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking shapes\n",
    "dbnvar_inv.shape,bnvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnvar          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbnvar\", dbnvar, bnvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bndiff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff2.shape,bnvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([207.5036], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff2[0].sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's essentially occuring is sum along 0'th axis of bnvar\n",
    "# multiplied by 1 /(n-1)\n",
    "# differentiation of addition is 1\n",
    "# dbnvar = 1/n-1 * torch.ones_like(bndiff2) -> for replication * dbnvar\n",
    "# local gradient -> bnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the shape of bndiff, since derivatives are 1\n",
    "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above we allowef broadcasting to take care of shape for us\n",
    "# bndiff2 -> (32, 64)\n",
    "# dbnvar -> (1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"bndiff2\", dbndiff2, bndiff2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbndiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How bndiff impacts bndiff2\n",
    "# bndiff2 = bnidff**2\n",
    "# local gradient = dbndiff2\n",
    "# dbndiff2/dbndiff = 2nbdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at shapes\n",
    "bndiff.shape, dbndiff2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st derivative\n",
    "dbndiff = (2.0 * bndiff) * dbndiff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd derivative\n",
    "dbndiff += bnvar_inv * dbnraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbndiff         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbndiff\", dbndiff, bndiff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbnmeani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how bnmeani impacts bndiff\n",
    "# local gradient = dbndiff\n",
    "# bndiff = hprebn - bnmeani\n",
    "# dbndiff/dbnmeani = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shapes\n",
    "bnmeani.shape, dbndiff.shape, hprebn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hprebn - bmeani has a broadcsting in forward pass\n",
    "# we've have to do a sum in backward pass to acheived bmeani shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnmeani = (-1.0 * dbndiff).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dbmeani\", dbnmeani, bnmeani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dhprebn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([64]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape, dbnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to dbnvar\n",
    "# treat 1/n*hprebn as x with sum along 0th dimension\n",
    "# gradient will be 1 /n \n",
    "\n",
    "### Derivation\n",
    "# bnmeani = 1 / n*hprebn_11 + 1/n*hprebn_12...\n",
    "# diff with respect to 11\n",
    "# dbnmeani/dhprebn_11 = 1/n*hprebn_11 * dhprebn_11\n",
    "# => 1\n",
    "###\n",
    "\n",
    "# local gradient -> dbnmeani\n",
    "# To achieve shape replicaton with ones_like(on hprebn)\n",
    "# Note: We've sum in forward pass replication in backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn = (1.0/n) * torch.ones_like(hprebn) * dbnmeani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhprebn         | exact: False | approximate: False | maxdiff: 0.0067764571867883205\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dhprebn\", dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WE also have another derivative of hprebn with respec to bndiff\n",
    "# graident 1\n",
    "# local gradient dndiff\n",
    "dbndiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn += dbndiff.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhprebn         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dhprebn\", dhprebn, hprebn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dembcat, dW1, db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([32, 64]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should be similar to h\n",
    "# local gradient -> dhprebn\n",
    "# let's check the shapes\n",
    "embcat.shape, W1.shape, b1.shape, dhprebn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]), torch.Size([32, 30]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To achieve embcat shape for dembcat\n",
    "dembcat = dhprebn @ W1.T\n",
    "dembcat.shape, embcat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dembcat         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dembcat\", dembcat, embcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW1             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# To achieve W1 shape (30, 64)\n",
    "# Transpose of embcat(30, 32) @ dhprebn (32, 64)\n",
    "dW1 = embcat.T @ dhprebn\n",
    "cmp(\"dW1\", dW1, W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To acheive db1 shpe (64) sum along 0th axis of  dhprebn\n",
    "# with keepdim False\n",
    "db1 = dhprebn.sum(0)\n",
    "db1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db1             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"db1\", db1, b1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]), torch.Size([32, 3, 10]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dembcat.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb influences embcat only via shape change using view\n",
    "# restoring demb to emb shape should be the gradients of emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demb            | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "demb = dembcat.view(32, 3, 10)\n",
    "cmp(\"demb\", demb, emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27, 10]), torch.Size([32, 3]), torch.Size([32, 3, 10]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape, Xb.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([11,  9, 14]),\n",
       " tensor([ 1.3183,  1.9677, -0.3339,  0.9639, -0.0383,  0.2375, -0.4943, -1.7681,\n",
       "          0.2730,  2.0455], grad_fn=<SelectBackward0>),\n",
       " tensor([ 0.7866,  0.1765,  0.8663,  0.1929, -0.1580,  0.0026,  0.8359,  0.3628,\n",
       "         -1.3720, -0.3301], grad_fn=<SelectBackward0>),\n",
       " tensor([-0.5153,  0.0259, -0.0321,  0.5640,  1.1713,  1.1885, -1.8572, -2.6870,\n",
       "          0.3759,  0.2415], grad_fn=<SelectBackward0>),\n",
       " tensor([[ 1.3183e+00,  1.9677e+00, -3.3387e-01,  9.6386e-01, -3.8280e-02,\n",
       "           2.3751e-01, -4.9429e-01, -1.7681e+00,  2.7301e-01,  2.0455e+00],\n",
       "         [ 7.8661e-01,  1.7654e-01,  8.6627e-01,  1.9289e-01, -1.5797e-01,\n",
       "           2.6419e-03,  8.3587e-01,  3.6276e-01, -1.3720e+00, -3.3006e-01],\n",
       "         [-5.1530e-01,  2.5901e-02, -3.2117e-02,  5.6398e-01,  1.1713e+00,\n",
       "           1.1885e+00, -1.8572e+00, -2.6870e+00,  3.7588e-01,  2.4146e-01]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb[0], C[11], C[9], C[14], emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In forward pass, we've looked up embedding of Xb from C\n",
    "# Now we've to route the gradients of each Xb index to dC\n",
    "# We'll have additive sum because a single index is looked up\n",
    "# multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC = torch.zeros_like(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[i, j]\n",
    "        # index of lookup to demb(gradients)\n",
    "        dC[ix] += demb[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dc              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dc\", dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = 1/probs * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
    "dcounts_sum = (-1.0/counts_sum**2) * dcounts_sum_inv\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits =  dnorm_logits.clone() # equivalent to 1 * dnorm_logits\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdims=True)\n",
    "# Another way of implementing \n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdims=True)\n",
    "dbnbias = dhpreact.clone().sum(0, keepdims=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdims=True)\n",
    "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff = (2.0 * bndiff) * dbndiff2\n",
    "dbndiff += bnvar_inv * dbnraw\n",
    "dbnmeani = (-1.0 * dbndiff).sum(0, keepdims=True)\n",
    "dhprebn = (1.0/n) * torch.ones_like(hprebn) * dbnmeani\n",
    "dhprebn += dbndiff.clone()\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(32, 3, 10)\n",
    "dC = torch.zeros_like(C)\n",
    "for i in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[i, j]\n",
    "        # index of lookup to demb(gradients)\n",
    "        dC[ix] += demb[i, j]\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy loss backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3746376037597656 diff: -2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast-loss).item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt crossentropy1](images/cross_entropy_1.jpeg)\n",
    "![Alt crossentropy1](images/cross_entropy_2.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on derivation\n",
    "# dlogits = Softmax(logits, 1) when logits != label\n",
    "# dlogits = dlogits - 1 where logits == label \n",
    "# For a batch loss is average of above loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.1158, -0.8226,  0.0609, -0.2619,  0.6964,  0.2490,  0.5152, -0.4327,\n",
       "         -0.9459,  0.5511, -0.4228, -0.2110,  0.1042,  0.0569,  0.1704,  1.0163,\n",
       "         -0.8796,  0.6179,  0.5209,  0.8504, -0.0297, -0.6321, -1.7548,  1.1942,\n",
       "          1.5577, -0.2835, -0.3905], grad_fn=<SelectBackward0>),\n",
       " tensor([0.0801, 0.0115, 0.0279, 0.0202, 0.0527, 0.0337, 0.0439, 0.0170, 0.0102,\n",
       "         0.0456, 0.0172, 0.0213, 0.0291, 0.0278, 0.0311, 0.0725, 0.0109, 0.0487,\n",
       "         0.0442, 0.0614, 0.0255, 0.0140, 0.0045, 0.0867, 0.1246, 0.0198, 0.0178],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0], dlogits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0801, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax implementation for logits_i(logits at ith index)\n",
    "torch.exp(torch.tensor(1.1158)) / torch.exp(logits[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0000, grad_fn=<SumBackward0>),\n",
       " tensor(2.2103, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax sum is 1\n",
    "dlogits[0].sum(), logits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0801,  0.0115,  0.0279,  0.0202,  0.0527,  0.0337,  0.0439, -0.9830,\n",
       "         0.0102,  0.0456,  0.0172,  0.0213,  0.0291,  0.0278,  0.0311,  0.0725,\n",
       "         0.0109,  0.0487,  0.0442,  0.0614,  0.0255,  0.0140,  0.0045,  0.0867,\n",
       "         0.1246,  0.0198,  0.0178], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.983"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dlogit at index 7\n",
    "0.0170 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average\n",
    "dlogits /= n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: False | approximate: True  | maxdiff: 8.381903171539307e-09\n"
     ]
    }
   ],
   "source": [
    "cmp(\"dlogits\", dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.xlabel(\"Characters\")\n",
    "plt.ylabel(\"Batch of inputs\")\n",
    "plt.imshow(dlogits.detach(), cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On visualizing the logits, if we see the 0th index at y axis(inputs) 7th index of x axis(27 characters) is negative -0.983 so highlighted in dark black.\n",
    "\n",
    "The derivatives are the gradients.\n",
    "\n",
    "What's essentially happending with derivatives is, we're pulling down the wrong probabalites(gray colored) and pulling up the correct probabalities(black colored). Since the sum of gradient across an input is zero, the push and pull are identitical.\n",
    "\n",
    "The neural network acts like a pulley system to push and pull gradients, which in turn affects the weight and biases. The push and pull is proportional to the corret and incorrect answer (i.e) probabalities in forward pass.\n",
    "\n",
    "> The amount of push pull in a dimension is proportinal to incorrect probabalities. The incorrectness is calculated by cross_entropy loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "21a124e163c92121797d725bed844fa6fdaf2c4e47bf1f149ef174ae791c682a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
